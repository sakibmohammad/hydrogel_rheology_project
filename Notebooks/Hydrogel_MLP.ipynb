{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "MLP for Regression"
      ],
      "metadata": {
        "id": "TbsUVP2Sl9TO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAojaDTflruY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import KFold\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "df = pd.read_csv('/content/Book1.csv')\n",
        "#df.info()\n",
        "\n",
        "dataset = df.values\n",
        "X = dataset[:, 0:7]\n",
        "\n",
        "input_dims = X.shape[1]\n",
        "Y = dataset[:, 7:9]\n",
        "#print(Y)\n",
        "output_dims = Y.shape[1]\n",
        "\n",
        "\n",
        "def evaluate_model(model, X_val, Y_val):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(X_val)\n",
        "        mae = mean_absolute_error(Y_val.cpu().detach().numpy(), predictions.cpu().detach().numpy())\n",
        "        r2 = r2_score(Y_val.cpu().detach().numpy(), predictions.cpu().detach().numpy())\n",
        "        mape = mean_absolute_percentage_error(Y_val.cpu().detach().numpy(), predictions.cpu().detach().numpy())\n",
        "        return mae, r2, mape\n",
        "\n",
        "def train_model(model, criterion, optimizer, X_train, Y_train, epochs):\n",
        "    for e in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X_train)\n",
        "        loss = criterion(output.squeeze(), Y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return model\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_layers, neurons, dropout_rate):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.hidden_layers = nn.ModuleList()\n",
        "\n",
        "        self.hidden_layers.append(nn.Linear(input_dim, neurons))\n",
        "        for i in range(hidden_layers - 1):\n",
        "            self.hidden_layers.append(nn.Linear(neurons, neurons))\n",
        "\n",
        "        self.output_layer = nn.Linear(neurons, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for hidden_layer in self.hidden_layers:\n",
        "            x = F.relu(hidden_layer(x))\n",
        "            x = self.dropout(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "hidden_layers = [2, 3, 4, 5]\n",
        "neurons = [128, 256, 512, 1024]\n",
        "dropout_rates = [0.2, 0.3, 0.5]\n",
        "epochs_list = [100, 200, 300]\n",
        "optimizers = [optim.SGD, optim.RMSprop, optim.Adam]\n",
        "learning_rates = [0.01, 0.001, 0.0005]\n",
        "\n",
        "kfold = KFold(n_splits = 10, shuffle = True)\n",
        "best_mae, best_r2, best_mape = float('inf'), float('-inf'), float('inf')\n",
        "best_params = {}\n",
        "\n",
        "for hidden_layer in hidden_layers:\n",
        "    for neuron in neurons:\n",
        "        for dropout_rate in dropout_rates:\n",
        "            for learning_rate in learning_rates:\n",
        "                for epoch in epochs_list:\n",
        "                    for opt in optimizers:\n",
        "                        mae_scores, r2_scores, mape_scores = [], [], []\n",
        "                        for train_index, val_index in kfold.split(X):\n",
        "                            X_train, X_val = X[train_index], X[val_index]\n",
        "                            Y_train, Y_val = Y[train_index], Y[val_index]\n",
        "\n",
        "                            scaler = MinMaxScaler()\n",
        "                            X_train = scaler.fit_transform(X_train)\n",
        "                            X_val = scaler.transform(X_val)\n",
        "\n",
        "                            X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "                            Y_train = torch.tensor(Y_train, dtype=torch.float32).to(device)\n",
        "                            X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
        "                            Y_val = torch.tensor(Y_val, dtype=torch.float32).to(device)\n",
        "\n",
        "                            model = Model(input_dims, output_dims, hidden_layer, neuron, dropout_rate).to(device)\n",
        "                            criterion = nn.SmoothL1Loss()\n",
        "                            optimizer = opt(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "                            model = train_model(model, criterion, optimizer, X_train, Y_train, epochs=epoch)\n",
        "                            mae, r2, mape = evaluate_model(model, X_val, Y_val)\n",
        "                            mae_scores.append(mae)\n",
        "                            r2_scores.append(r2)\n",
        "                            mape_scores.append(mape)\n",
        "\n",
        "                        avg_mae, avg_r2, avg_mape = np.mean(mae_scores), np.mean(r2_scores), np.mean(mape_scores)\n",
        "                        std_mae, std_r2, std_mape = np.std(mae_scores), np.std(r2_scores), np.std(mape_scores)\n",
        "\n",
        "\n",
        "                        if avg_mae < best_mae and avg_r2 > best_r2 and avg_mape<best_mape:\n",
        "                            best_mae, best_r2, best_mape = avg_mae, avg_r2, avg_mape\n",
        "                            best_params = {'hidden_layers': hidden_layer, 'neurons': neuron, 'dropout_rate': dropout_rate, 'learning_rate': learning_rate, 'optimizer': opt, 'epochs': epoch}\n",
        "\n",
        "print('Best Parameters: ', best_params)\n",
        "print(\"Best Mean Absolute Error (MAE): \", best_mae)\n",
        "print(\"Best Mean Absolute Percentage Error (MAPE): \", best_mape)\n",
        "print('Best R^2 Score: ', best_r2)\n",
        "print('Std of MAE: ', std_mae)\n",
        "print('Std of MAPE: ', std_mape)\n",
        "print('Std of R^2: ', std_r2)"
      ]
    }
  ]
}